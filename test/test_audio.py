#!/usr/bin/env python3
"""è¯­éŸ³é©±åŠ¨ Agent - ç»ˆç«¯ç‰ˆ"""

import anyio
import io
import wave
import time
import os
import sys
import requests
import pyaudio
import webrtcvad
from typing import Optional

from claude_agent_sdk import query, ClaudeAgentOptions


class AudioRecorder:
    """éŸ³é¢‘å½•åˆ¶å™¨ï¼Œæ”¯æŒè¯­éŸ³ç«¯ç‚¹æ£€æµ‹(VAD)"""

    def __init__(
        self,
        sample_rate: int = 16000,
        frame_duration_ms: int = 30,
        padding_duration_ms: int = 300,
        input_device_index: int = None,
    ):
        self.sample_rate = sample_rate
        self.frame_duration_ms = frame_duration_ms
        self.padding_duration_ms = padding_duration_ms
        self.input_device_index = input_device_index
        self.vad = webrtcvad.Vad(2)

    @staticmethod
    def list_devices():
        """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„éŸ³é¢‘è®¾å¤‡"""
        audio = pyaudio.PyAudio()
        print("\n=== å¯ç”¨çš„éŸ³é¢‘è®¾å¤‡ ===")
        for i in range(audio.get_device_count()):
            info = audio.get_device_info_by_index(i)
            if info["maxInputChannels"] > 0:
                print(f"è¾“å…¥è®¾å¤‡ {i}: {info['name']}")
            if info["maxOutputChannels"] > 0:
                print(f"è¾“å‡ºè®¾å¤‡ {i}: {info['name']}")
        print("=" * 30 + "\n")
        audio.terminate()

    def record_until_silence(self, timeout: int = 100) -> bytes:
        """å½•éŸ³ç›´åˆ°æ£€æµ‹åˆ°é™éŸ³ï¼ˆè¯­éŸ³ç»“æŸï¼‰æˆ–è¶…æ—¶"""
        print("ğŸ¤ è¯·å¼€å§‹è¯´è¯ï¼ˆè‡ªåŠ¨æ£€æµ‹è¯­éŸ³ç»“æŸï¼‰...")

        audio = pyaudio.PyAudio()
        frame_size = int(self.sample_rate * self.frame_duration_ms / 1000)

        if self.input_device_index is not None:
            device_info = audio.get_device_info_by_index(self.input_device_index)
            print(f"ğŸ§ ä½¿ç”¨è®¾å¤‡: {device_info['name']}")

        stream = audio.open(
            format=pyaudio.paInt16,
            channels=1,
            rate=self.sample_rate,
            input=True,
            input_device_index=self.input_device_index,
            frames_per_buffer=frame_size,
        )

        frames = []
        num_padding_frames = int(self.padding_duration_ms / self.frame_duration_ms)
        ring_buffer = []
        triggered = False
        start_time = time.time()
        trigger_threshold = 1

        try:
            while True:
                if time.time() - start_time > timeout:
                    print("âš ï¸  å½•éŸ³è¶…æ—¶")
                    break

                frame = stream.read(frame_size, exception_on_overflow=False)
                is_speech = self.vad.is_speech(frame, self.sample_rate)

                if not triggered:
                    ring_buffer.append((frame, is_speech))
                    num_voiced = len([f for f, speech in ring_buffer if speech])
                    if len(ring_buffer) >= trigger_threshold and num_voiced >= 1:
                        triggered = True
                        frames.extend([f for f, s in ring_buffer])
                        ring_buffer.clear()
                        print("ğŸ”´ å¼€å§‹å½•éŸ³...")
                else:
                    frames.append(frame)
                    ring_buffer.append((frame, is_speech))
                    num_unvoiced = len([f for f, speech in ring_buffer if not speech])
                    if num_unvoiced >= num_padding_frames:
                        print("â¹ï¸  æ£€æµ‹åˆ°è¯­éŸ³ç»“æŸ")
                        break

        except KeyboardInterrupt:
            print("\nâ¹ï¸  æ‰‹åŠ¨åœæ­¢å½•éŸ³")

        finally:
            stream.stop_stream()
            stream.close()
            audio.terminate()

        pcm_data = b"".join(frames)

        if len(frames) < 10:
            print("âš ï¸  å½•éŸ³æ—¶é—´å¤ªçŸ­ï¼Œæœªä¿å­˜")
            return b""

        return pcm_data


class SiliconFlowASR:
    """SiliconFlow è¯­éŸ³è¯†åˆ«å®¢æˆ·ç«¯"""

    API_URL = "https://api.siliconflow.cn/v1/audio/transcriptions"

    def __init__(self, api_key: str):
        self.api_key = api_key

    def transcribe(
        self, audio_data: bytes, model: str = "TeleAI/TeleSpeechASR"
    ) -> Optional[str]:
        """è¯†åˆ«è¯­éŸ³å¹¶è¿”å›æ–‡æœ¬"""
        headers = {"Authorization": f"Bearer {self.api_key}"}
        files = {"file": ("audio.wav", io.BytesIO(audio_data), "audio/wav")}
        data = {"model": model}

        try:
            print("ğŸ¤– æ­£åœ¨è¯†åˆ«...")
            response = requests.post(
                self.API_URL, headers=headers, files=files, data=data, timeout=30
            )
            response.raise_for_status()

            result = response.json()
            text = result.get("text", "")

            if text:
                return text
            else:
                print(f"âš ï¸  API è¿”å›å¼‚å¸¸: {result}")
                return None

        except requests.exceptions.RequestException as e:
            print(f"âŒ è¯·æ±‚å¤±è´¥: {e}")
            return None
        except Exception as e:
            print(f"âŒ é”™è¯¯: {e}")
            return None


class VoiceAgent:
    """è¯­éŸ³é©±åŠ¨çš„ Claude Agent"""

    def __init__(self, api_key: str, input_device_index: int = None):
        self.recorder = AudioRecorder(
            input_device_index=input_device_index, sample_rate=16000
        )
        self.recorder.vad = webrtcvad.Vad(0)
        self.asr = SiliconFlowASR(api_key)

    async def process_voice_command(self, voice_prompt: str):
        """å¤„ç†è¯­éŸ³å‘½ä»¤å¹¶é€šè¿‡ Agent æ‰§è¡Œ"""

        options = ClaudeAgentOptions(
            model="glm-4.7-flash",
            permission_mode="bypassPermissions",
            max_turns=5,
        )

        print(f"\nğŸ¤– Agent æ‰§è¡Œä¸­...")
        print("-" * 40)

        async for message in query(prompt=voice_prompt, options=options):
            print(message, end="", flush=True)

        print("\n" + "-" * 40)

    def run(self):
        """ä¸»å¾ªç¯"""
        print("\n" + "=" * 50)
        print("ğŸ™ï¸  è¯­éŸ³é©±åŠ¨ Agent")
        print("=" * 50)
        print("ä½¿ç”¨æ–¹æ³•:")
        print("1. æŒ‰ Enter å¼€å§‹å½•éŸ³")
        print("2. å¯¹ç€éº¦å…‹é£è¯´å‡ºä½ çš„æŒ‡ä»¤")
        print("3. è¯´å®Œåç­‰å¾…è‡ªåŠ¨åœæ­¢")
        print("4. Agent å°†æ‰§è¡Œä½ çš„æŒ‡ä»¤")
        print("5. è¾“å…¥ 'q' é€€å‡ºç¨‹åº")
        print("=" * 50 + "\n")

        while True:
            try:
                user_input = input("æŒ‰ Enter å¼€å§‹å½•éŸ³ (è¾“å…¥ q é€€å‡º): ").strip().lower()
                if user_input == "q":
                    print("ğŸ‘‹ å†è§!")
                    break

                pcm_data = self.recorder.record_until_silence(timeout=30)

                if not pcm_data:
                    continue

                wav_buffer = io.BytesIO()
                with wave.open(wav_buffer, "wb") as wf:
                    wf.setnchannels(1)
                    wf.setsampwidth(2)
                    wf.setframerate(16000)
                    wf.writeframes(pcm_data)
                wav_data = wav_buffer.getvalue()

                text = self.asr.transcribe(wav_data)

                if text:
                    print(f"\nğŸ“ è¯†åˆ«åˆ°çš„æŒ‡ä»¤: {text}")
                    anyio.run(self.process_voice_command, text)
                else:
                    print("\nâŒ æœªèƒ½è¯†åˆ«åˆ°æ–‡å­—\n")

            except KeyboardInterrupt:
                print("\nğŸ‘‹ ç¨‹åºå·²ç»ˆæ­¢")
                break
            except Exception as e:
                print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}\n")


def main():
    api_key = os.environ.get(
        "SILICONFLOW_API_KEY", "sk-mzwuunvvjoamyfgslvepqnpkguepjetgiumodtrrtcmirfya"
    )
    input_device = 1
    agent = VoiceAgent(api_key=api_key, input_device_index=input_device)
    agent.run()


if __name__ == "__main__":
    main()
